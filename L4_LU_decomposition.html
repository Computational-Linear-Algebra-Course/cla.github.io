
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>4. LU decomposition &#8212; Computational linear algebra course 2020.0 documentation</title>
    <link rel="stylesheet" href="_static/fenics.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/proof.js"></script>
    <script async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="3. Analysing algorithms" href="L3_analysing_algorithms.html" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

<link rel="stylesheet" href="_static/featured.css">


<link rel="shortcut icon" href="_static/icon.ico" />


  </head><body>
<div class="wrapper">
  <a href="index.html"><img src="_static/banner.png" width="900px" alt="Project Banner" /></a>
  <div id="access">
    <div class="menu">
      <ul>
          <li class="page_item"><a href="https://github.com/Computational-Linear-Algebra-Course/computational-linear-algebra-course" title="GitHub">GitHub</a></li>
      </ul>
    </div><!-- .menu -->
  </div><!-- #access -->
</div><!-- #wrapper -->


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="lu-decomposition">
<h1><span class="section-number">4. </span>LU decomposition<a class="headerlink" href="#lu-decomposition" title="Permalink to this headline">¶</a></h1>
<p>In this section we look at the some other algorithms for solving the
equation <span class="math notranslate nohighlight">\(Ax=b\)</span> when <span class="math notranslate nohighlight">\(A\)</span> is invertible. On the one hand the <span class="math notranslate nohighlight">\(QR\)</span>
factorisation has great stability properties. On the other, it can be
beaten by other methods for speed when there is particular structure
to exploit (such as lots of zeros in the matrix). In this section, we
explore the the family of methods that go right back to the technique
of Gaussian elimination, that you will have been familiar with since
secondary school.</p>
<div class="section" id="an-algorithm-for-lu-decomposition">
<h2><span class="section-number">4.1. </span>An algorithm for LU decomposition<a class="headerlink" href="#an-algorithm-for-lu-decomposition" title="Permalink to this headline">¶</a></h2>
<p>The computational way to view Gaussian elimination is through the LU
decomposition of an invertible matrix, <span class="math notranslate nohighlight">\(A=LU\)</span>, where <span class="math notranslate nohighlight">\(L\)</span> is lower
triangular (<span class="math notranslate nohighlight">\(l_{ij}=0\)</span> for <span class="math notranslate nohighlight">\(j&lt;i\)</span>) and <span class="math notranslate nohighlight">\(U\)</span> is upper triangular
(<span class="math notranslate nohighlight">\(u_{ij}=0\)</span> for <span class="math notranslate nohighlight">\(j&gt;i\)</span>). Here we use the symbol <span class="math notranslate nohighlight">\(U\)</span> instead of <span class="math notranslate nohighlight">\(R\)</span> to
emphasise that we are looking as square matrices.  The process of
obtaining the <span class="math notranslate nohighlight">\(LU\)</span> decomposition is very similar to the Householder
algorithm, in that we repeatedly left multiply <span class="math notranslate nohighlight">\(A\)</span> by matrices to
transform below-diagonal entries in each column to zero, working from
the first to the last column. The difference is that whilst the
Householder algorithm left multiplies with unitary matrices, here,
we left multiply with lower triangular matrices.</p>
<p>The first step puts zeros below the first entry in the first column.</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}A_1 = L_1A = \begin{pmatrix}
u_1 &amp; v_2^1 &amp; v_2^1 &amp; \ldots &amp; v_n^1 \\
\end{pmatrix},\end{split}\\\begin{split}\,
u_1 = \begin{pmatrix} u_{11} \\ 0 \\ \ldots \\ 0\end{pmatrix}.\end{split}\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>Then, the next step puts zeros  below the second entry in the second
column.</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}A_2 = L_2L_1A = \begin{pmatrix}
u_1 &amp; u_2 &amp; v_2^2 &amp; \ldots &amp; v_n^2 \\
\end{pmatrix},\end{split}\\\begin{split}\,
u_2 = \begin{pmatrix} u_{12} \\ u_{22} \\ 0 \\ \ldots \\ 0 \\
\end{pmatrix}.\end{split}\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>After repeated left multiplications we have</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[A_n = \underbrace{L_n\ldots L_2L_1}A = U.\]</div>
</div></blockquote>
<p>If we assume (we will show this later) that all these lower triangular
matrices are invertible, we can define</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}L = (L_n\ldots L_2L_1)^{-1} = L_1^{-1}L_2^{-1}\ldots L_n^{-1},\\\mbox{ so that }\\L^{-1} = L_n\ldots L_2L_1.\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>Then we have <span class="math notranslate nohighlight">\(L^{-1}A = U\)</span>, i.e. <span class="math notranslate nohighlight">\(A=LU\)</span>.</p>
<p>So, we need to find lower triangular matrices <span class="math notranslate nohighlight">\(L_k\)</span> that do not change
the first <span class="math notranslate nohighlight">\(k-1\)</span> rows, and transforms the kth column ‘x_k’ of <span class="math notranslate nohighlight">\(A_k\)</span>
as follows.</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}Lx_k = L\begin{pmatrix}
x_{1k}\\
\vdots\\
x_{kk}\\
x_{k+1,k}\\
\vdots\\
x_{m,k}\\
\end{pmatrix}
= \begin{pmatrix}
x_{1k}\\
\vdots\\
x_{kk}\\
0 \\
\vdots\\
0 \\
\end{pmatrix}.\end{split}\]</div>
</div></blockquote>
<p>As before with the Householder method, we see that we need the top-left
<span class="math notranslate nohighlight">\(k\times k\)</span> submatrix of <span class="math notranslate nohighlight">\(L\)</span> to be the identity (so that it doesn’t change
the first <span class="math notranslate nohighlight">\(k\)</span> rows). We claim that the following matrix transforms
<span class="math notranslate nohighlight">\(x_k\)</span> to the required form.</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}L_k = \begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; \ldots &amp; 0 &amp; \ldots &amp; \ldots &amp; \ldots &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; \ldots &amp; 0 &amp; \ldots &amp; \ldots&amp; \vdots &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; \ldots &amp; 0 &amp; \ldots &amp; \ldots &amp; \vdots &amp; 0 \\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; 0 \\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; 1 &amp; 0 &amp; \ldots &amp; \vdots &amp; 0 \\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; -l_{k+1,k} &amp; 1 &amp; \ldots &amp; \vdots &amp; 0 \\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; -l_{k+2,k} &amp; 0 &amp; \ddots &amp; \vdots &amp; 0 \\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \vdots &amp; 0 &amp; \ldots &amp; \ddots &amp; 0 \\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; -l_{m,k} &amp; 0 &amp; \ldots &amp; \ldots &amp;1 \\
\end{pmatrix},\end{split}\\\quad\\\begin{split}l_k = \begin{pmatrix}
0 \\
0 \\
0 \\
\vdots \\
0 \\
l_{k+1,k}=x_{k+1,k}/x_{kk} \\
l_{k+2,k}= x_{k+2,k}/x_{kk} \\
\vdots\\
l_{m,k} = x_{m,k}/x_{kk} \\
\end{pmatrix}.\end{split}\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>This has the identity block as required, and we can verify that <span class="math notranslate nohighlight">\(L_k\)</span>
puts zeros in the entries of <span class="math notranslate nohighlight">\(x_k\)</span> below the diagonal by first writing
<span class="math notranslate nohighlight">\(L_k = I - l_ke_k^*\)</span>. Then,</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[L_kx_k = I - l_ke_k^* = x_k - l_k\underbrace{(e_k^*x_k)}_{=x_{kk}},\]</div>
</div></blockquote>
<p>which subtracts off the below diagonal entries as required.</p>
<p>The determinant of a lower triangular martix is equal to the trace
(product of diagonal entries), so <span class="math notranslate nohighlight">\(\det(L_k)=1\)</span>, and consequently
<span class="math notranslate nohighlight">\(L_k\)</span> is invertible, enabling us to define <span class="math notranslate nohighlight">\(L^{-1}\)</span> as above.
To form <span class="math notranslate nohighlight">\(L\)</span> we need to multiply the inverses of all the <span class="math notranslate nohighlight">\(L_k\)</span> matrices
together, also as above. To do this, we first note that <span class="math notranslate nohighlight">\(l_k^*e_k=0\)</span>
(because <span class="math notranslate nohighlight">\(l_k\)</span> is zero in the only entry that <span class="math notranslate nohighlight">\(e_k\)</span> is nonzero). Then
we claim that <span class="math notranslate nohighlight">\(L_k^{-1}=I + l_ke_k^*\)</span>, which we verify as follows.</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}(I + l_ke_k^*)L_k =       (I + l_ke_k^*)(I - l_ke_k^*)
= I + l_ke_k^* - l_ke_k^* + (l_ke_k^*)(l_ke_k*)\\= I + \underbrace{l_k(e_k^*l_k)e_k*}_{=0} = I,\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>as required. Similarly if we multiply the inverse lower triangular
matrices from two consecutive iterations, we get</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}L_k^{-1}L_{k+1}^{-1} = (I + l_ke_k^*)(I + l_{k+1}e_{k+1}^*)
= I + l_ke_k^* + l_{k+1}e_{k+1}^* + l_k\underbrace{(e_k^*l_{k+1})}_{=0}e_{k+1}^*\\= I + l_ke_k^* + l_{k+1}e_{k+1}^*,\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>since <span class="math notranslate nohighlight">\(e_k^*l_{k+1}=0\)</span> too, as <span class="math notranslate nohighlight">\(l_{k+1}\)</span> is zero in the only place
where <span class="math notranslate nohighlight">\(e_k\)</span> is nonzero. If we iterate this argument, we get</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[L = I + \sum_{i=1}^{m-1}l_ie_i^*.\]</div>
</div></blockquote>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Colin J. Cotter.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.1.2.
    </div>
  </body>
</html>